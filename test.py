import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs
import openai

# ğŸ” API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = "sk-..."  # â† ë³¸ì¸ì˜ í‚¤ë¡œ êµì²´
openai.api_key = os.environ["OPENAI_API_KEY"]

# âœ… ë„¤ì´ë²„ ë¸”ë¡œê·¸ Access Token (OAuth 2.0 í†µí•´ ìˆ˜ë™ ë°œê¸‰ í•„ìš”)
NAVER_ACCESS_TOKEN = "YOUR_NAVER_ACCESS_TOKEN"

# -----------------------------------------------------------
# [1] ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§
# -----------------------------------------------------------
def extract_blog_text(blog_url):
    try:
        # Step 1: ë¸”ë¡œê·¸ ê¸€ ID ì¶”ì¶œ
        parsed = urlparse(blog_url)
        query = parse_qs(parsed.query)
        blogId = query.get('blogId', [''])[0]
        logNo = query.get('logNo', [''])[0]

        # Step 2: iframeìœ¼ë¡œ ì‹¤ì œ ë³¸ë¬¸ HTML ë¶ˆëŸ¬ì˜¤ê¸°
        iframe_url = f"https://blog.naver.com/PostView.nhn?blogId={blogId}&logNo={logNo}"
        res = requests.get(iframe_url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, "html.parser")

        # Step 3: ë³¸ë¬¸ ì¶”ì¶œ
        main_frame = soup.select_one("iframe#mainFrame")
        if main_frame:
            real_url = "https://blog.naver.com" + main_frame["src"]
            res2 = requests.get(real_url, headers={"User-Agent": "Mozilla/5.0"})
            soup2 = BeautifulSoup(res2.text, "html.parser")
            content = soup2.select_one("div.se-main-container")
            if not content:
                content = soup2.select_one("#postViewArea")
            return content.get_text(strip=True) if content else ""
        else:
            return ""
    except Exception as e:
        print(f"[Error] {blog_url}: {e}")
        return ""

# -----------------------------------------------------------
# [2] í‚¤ì›Œë“œ ë° ë¬¸ì²´ ë¶„ì„ (GPT ê¸°ë°˜)
# -----------------------------------------------------------
def analyze_with_gpt(texts):
    combined_text = "\n\n".join(texts)[:8000]  # GPT token ì œí•œ ê³ ë ¤
    prompt = f"""
ë‹¤ìŒì€ ì¸ê¸° ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ ëª¨ìŒì´ì•¼. ì´ ê¸€ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ê³µí†µëœ í•µì‹¬ í‚¤ì›Œë“œì™€ ìƒìœ„ ë…¸ì¶œì„ ìœ„í•œ ë¬¸ì²´/êµ¬ì¡° íŠ¹ì§•ì„ ì•Œë ¤ì¤˜.

1. ìì£¼ ë“±ì¥í•˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œ 5~7ê°œ
2. ë¬¸ì²´(ì˜ˆ: ì¹œê·¼í•œ ë§íˆ¬, ì§ˆë¬¸í˜• ì œëª© ë“±)
3. ê¸€ êµ¬ì„± ë°©ì‹ ìš”ì•½ (ì˜ˆ: ì„œë¡ -ì§ˆë¬¸-ë³¸ë¬¸-ê²°ë¡ )

ë¸”ë¡œê·¸ ê¸€ ëª¨ìŒ:
\"\"\"
{combined_text}
\"\"\"
    """
    res = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )
    return res.choices[0].message.content.strip()

# -----------------------------------------------------------
# [3] ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ì˜ ë¸”ë¡œê·¸ ê¸€ ìë™ ìƒì„±
# -----------------------------------------------------------
def generate_similar_blog(style_analysis, topic="ìš”ì¦˜ ì¸ê¸° ë§ì€ ì—¬í–‰ì§€ ì¶”ì²œ"):
    prompt = f"""
ë„ˆëŠ” ë¸”ë¡œê·¸ ë§ˆì¼€í„°ì•¼. ì•„ë˜ ìŠ¤íƒ€ì¼ ë¶„ì„ì„ ì°¸ê³ í•´ì„œ '{topic}'ì— ëŒ€í•œ ë¸”ë¡œê·¸ ê¸€ì„ ì¨ì¤˜.

ìŠ¤íƒ€ì¼ ë¶„ì„:
{style_analysis}

ì¡°ê±´:
- ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì„±
- ê¸€ ê¸¸ì´ 1200ì ì´ìƒ
- ì¹œê·¼í•˜ê³  ì‹ ë¢°ê°€ëŠ” ë§íˆ¬
- ë…ìê°€ ê´€ì‹¬ì„ ê°€ì§ˆ ë§Œí•œ í¬ì¸íŠ¸ ê°•ì¡°

ì§€ê¸ˆ ë°”ë¡œ ì¨ì¤˜:
"""
    res = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8,
    )
    return res.choices[0].message.content.strip()

# -----------------------------------------------------------
# [4] ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìë™ í¬ìŠ¤íŒ…
# -----------------------------------------------------------
def upload_to_naver_blog(title, content):
    url = "https://openapi.naver.com/blog/writePost.json"
    headers = {
        "Authorization": f"Bearer {NAVER_ACCESS_TOKEN}"
    }
    data = {
        "title": title,
        "contents": content
    }
    response = requests.post(url, headers=headers, data=data)
    if response.status_code == 200:
        print("âœ… ë¸”ë¡œê·¸ ì—…ë¡œë“œ ì™„ë£Œ!")
    else:
        print("âŒ ì—…ë¡œë“œ ì‹¤íŒ¨:", response.text)

# -----------------------------------------------------------
# [5] ì „ì²´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
# -----------------------------------------------------------
def run_auto_blog_pipeline(blog_urls, topic):
    print("â–¶ ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ ì¤‘...")
    texts = [extract_blog_text(url) for url in blog_urls]
    texts = [t for t in texts if t]

    print("â–¶ ìŠ¤íƒ€ì¼ ë° í‚¤ì›Œë“œ ë¶„ì„ ì¤‘...")
    style_info = analyze_with_gpt(texts)

    print("â–¶ ìë™ ê¸€ ì‘ì„± ì¤‘...")
    new_article = generate_similar_blog(style_info, topic)

    print("â–¶ ë¸”ë¡œê·¸ ì—…ë¡œë“œ ì¤‘...")
    upload_to_naver_blog(f"{topic}ì— ëŒ€í•´ ì•Œì•„ë³´ì", new_article)

# -----------------------------------------------------------
# â–¶ ì‹¤í–‰ ì˜ˆì‹œ
# -----------------------------------------------------------
if __name__ == "__main__":
    blog_urls = [
        "https://blog.naver.com/abc123?Redirect=Log&logNo=123456789",
        "https://blog.naver.com/def456?Redirect=Log&logNo=234567890",
        # ... ì´ 10ê°œ ì…ë ¥
    ]
    user_topic = "ê°€ì„ ì œì£¼ë„ ì—¬í–‰ì§€ ì¶”ì²œ"
    run_auto_blog_pipeline(blog_urls, user_topic)
